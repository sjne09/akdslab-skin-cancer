{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.chdir(\"..\")\n",
    "\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from operator import itemgetter\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from data_models.datasets import (\n",
    "    EnsembleDataset,\n",
    "    SlideClassificationDataset,\n",
    "    SlideEncodingDataset,\n",
    ")\n",
    "from data_models.Label import Label\n",
    "from models.ensemble import EnsembleClassifier\n",
    "from utils.eval import Evaluator\n",
    "from utils.load_data import load_data\n",
    "from utils.split import train_val_split_labels, train_val_split_slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = os.path.join(DATA_DIR, \"labels/labels.csv\")\n",
    "fold_path = os.path.join(DATA_DIR, \"folds.json\")\n",
    "\n",
    "df = load_data(label_path=label_path, fold_path=fold_path)\n",
    "df = df.set_index(\"specimen_id\")\n",
    "labels_onehot = df[Label._member_names_].to_dict(orient=\"split\", index=True)\n",
    "labels_onehot = {\n",
    "    k: np.array(labels_onehot[\"data\"][i])\n",
    "    for i, k in enumerate(labels_onehot[\"index\"])\n",
    "}\n",
    "labels_dict = {row.name: int(row[\"label\"]) for _, row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of specimens within each fold\n",
    "specimens_by_fold = df.groupby(\"fold\").groups\n",
    "specimens_by_fold = [list(specs) for specs in specimens_by_fold.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freqs = {\n",
    "    label: df[label].value_counts(normalize=True).iloc[1]\n",
    "    for label in Label._member_names_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(\n",
    "    val_fold: int,\n",
    "    specimens_by_fold: List[List[str]],\n",
    "    slides_by_specimen: Dict[str, List[str]],\n",
    "    labels_by_specimen: Dict[str, int],\n",
    "    tile_embed_paths: List[Dict[str, str]],\n",
    "    slide_embed_paths: Optional[List[str]] = None,\n",
    ") -> Tuple[EnsembleDataset, EnsembleDataset]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    tile_embed_paths : List[Dict[str, str]]\n",
    "        A list of tile embedding paths for different models. Each item in\n",
    "        the list must be a dict with slide ids as keys and paths to tile\n",
    "        embed pkl files as values\n",
    "\n",
    "    slide_embed_paths : List[str]\n",
    "        A list of slide embedding paths for different models. Each item in\n",
    "        the list must be a path to a slide embed pkl file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[EnsembleDataset, EnsembleDataset]\n",
    "        Train, val datasets\n",
    "    \"\"\"\n",
    "    # get the train and val splits\n",
    "    train, val = train_val_split_slides(\n",
    "        val_fold=val_fold,\n",
    "        specimens_by_fold=specimens_by_fold,\n",
    "        slides_by_specimen=slides_by_specimen,\n",
    "    )\n",
    "    train_labels, val_labels = train_val_split_labels(\n",
    "        val_fold=val_fold,\n",
    "        labels_by_specimen=labels_by_specimen,\n",
    "        specimens_by_fold=specimens_by_fold,\n",
    "    )\n",
    "\n",
    "    # get the train sets\n",
    "    train_slide_encoder_datasets = [\n",
    "        SlideEncodingDataset(list(itemgetter(*train)(paths)), train_labels)\n",
    "        for paths in tile_embed_paths\n",
    "    ]\n",
    "    if slide_embed_paths is not None:\n",
    "        train_slide_classifier_datasets = [\n",
    "            SlideClassificationDataset(path, train, train_labels)\n",
    "            for path in slide_embed_paths\n",
    "        ]\n",
    "    else:\n",
    "        train_slide_classifier_datasets = []\n",
    "\n",
    "    # get the val sets\n",
    "    val_slide_encoder_datasets = [\n",
    "        SlideEncodingDataset(list(itemgetter(*val)(paths)), val_labels)\n",
    "        for paths in tile_embed_paths\n",
    "    ]\n",
    "    if slide_embed_paths is not None:\n",
    "        val_slide_classifier_datasets = [\n",
    "            SlideClassificationDataset(path, val, val_labels)\n",
    "            for path in slide_embed_paths\n",
    "        ]\n",
    "    else:\n",
    "        val_slide_classifier_datasets = []\n",
    "\n",
    "    # construct the ensemble sets\n",
    "    train_set = EnsembleDataset(\n",
    "        train_slide_encoder_datasets, train_slide_classifier_datasets\n",
    "    )\n",
    "    val_set = EnsembleDataset(\n",
    "        val_slide_encoder_datasets, val_slide_classifier_datasets\n",
    "    )\n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_model_input(\n",
    "    sample: Tuple[List[Dict[str, Any]], List[Dict[str, Any]]],\n",
    "    device: torch.device,\n",
    ") -> Tuple[\n",
    "    List[torch.Tensor],\n",
    "    List[torch.Tensor],\n",
    "    List[torch.Tensor],\n",
    "    torch.Tensor,\n",
    "    str,\n",
    "]:\n",
    "    tile, slide = sample\n",
    "\n",
    "    # add batch dim and collate\n",
    "    tile_embeds = []\n",
    "    coords = []\n",
    "    slide_embeds = []\n",
    "    label = None\n",
    "    slide_id = None\n",
    "    for embed in tile:\n",
    "        tile_embeds.append(embed[\"tile_embeds\"].unsqueeze(0).to(device))\n",
    "        coords.append(embed[\"pos\"].unsqueeze(0).to(device))\n",
    "        label = embed[\"label\"]\n",
    "        slide_id = embed[\"id\"]\n",
    "\n",
    "    for embed in slide:\n",
    "        slide_embeds.append(embed[\"slide_embed\"].unsqueeze(0).to(device))\n",
    "        label = embed[\"label\"]\n",
    "        slide_id = embed[\"id\"]\n",
    "\n",
    "    label = torch.tensor([label]).to(device)\n",
    "\n",
    "    return tile_embeds, coords, slide_embeds, label, slide_id\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: EnsembleClassifier,\n",
    "    dataset: EnsembleDataset,\n",
    "    optimizer: torch.optim,\n",
    "    loss_fn: nn.Module,\n",
    "    grad_accum_steps: int,\n",
    "    device: torch.device,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Trains an epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The model to train\n",
    "\n",
    "    dataset : Dataset\n",
    "        The dataset for the training data\n",
    "\n",
    "    optimizer : torch.optim\n",
    "        The optimizer\n",
    "\n",
    "    loss_fn : nn.Module\n",
    "        The loss function\n",
    "\n",
    "    grad_accum_steps : int\n",
    "        The number of batches/samples to accumulate gradients for before\n",
    "        updating the model\n",
    "\n",
    "    device : torch.device\n",
    "        The device to send the model and data to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The average training loss for the epoch\n",
    "    \"\"\"\n",
    "    agg_loss = 0.0\n",
    "    model = model.to(device) if device else model\n",
    "    model.train()\n",
    "    order = np.random.permutation(len(dataset))\n",
    "    for n, i in enumerate(order):\n",
    "        tile_embeds, coords, slide_embeds, label, _ = prep_model_input(\n",
    "            dataset[i], device\n",
    "        )\n",
    "\n",
    "        logits = model.forward(tile_embeds, coords, slide_embeds)\n",
    "        loss = loss_fn(logits, label)\n",
    "        loss.backward()\n",
    "        agg_loss += loss.item()\n",
    "\n",
    "        # accumulate grad until grad_accum_steps is reached\n",
    "        if (n + 1) % grad_accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # ensure no remaining accumulated grad\n",
    "    if (n + 1) % grad_accum_steps != 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return agg_loss / (n + 1)\n",
    "\n",
    "\n",
    "def val_epoch(\n",
    "    model: EnsembleClassifier,\n",
    "    dataset: EnsembleDataset,\n",
    "    device: torch.device,\n",
    "    loss_fn: Optional[nn.Module] = None,\n",
    ") -> Tuple[float, torch.Tensor, torch.Tensor, List[str]]:\n",
    "    \"\"\"\n",
    "    Validates an epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The model to validate\n",
    "\n",
    "    dataset : Dataset\n",
    "        The dataset for the validation data\n",
    "\n",
    "    device : torch.device\n",
    "        The device to send the model and data to\n",
    "\n",
    "    loss_fn : nn.Module, optional\n",
    "        The loss function; if not provided no loss will be calculated\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The average training loss for the epoch; if loss_fn is not provided\n",
    "        this will be 0\n",
    "\n",
    "    torch.Tensor\n",
    "        The labels for the validation data\n",
    "\n",
    "    torch.Tensor\n",
    "        The model outputs for the validation data (softmaxed logits)\n",
    "\n",
    "    List[str]\n",
    "        The IDs for the validation data\n",
    "    \"\"\"\n",
    "    agg_loss = 0.0\n",
    "    outputs = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for i, sample in enumerate(dataset):\n",
    "            tile_embeds, coords, slide_embeds, label, slide_id = (\n",
    "                prep_model_input(sample, device)\n",
    "            )\n",
    "\n",
    "            logits = model(tile_embeds, coords, slide_embeds)\n",
    "            if loss_fn is not None:\n",
    "                loss = loss_fn(logits, label)\n",
    "                agg_loss += loss.item()\n",
    "\n",
    "            outputs.append(torch.softmax(logits.detach().cpu(), dim=-1))\n",
    "            labels.append(label)\n",
    "            ids.append(slide_id)\n",
    "    outputs = torch.cat(outputs)\n",
    "    labels = torch.cat(labels)\n",
    "    return agg_loss / (i + 1), labels, outputs, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tile embedding paths for each tile encoder model\n",
    "def get_tile_embed_paths(tile_embed_dir: str) -> Dict[str, str]:\n",
    "    fnames = os.listdir(tile_embed_dir)\n",
    "    fnames.sort()\n",
    "    tile_embed_paths = {\n",
    "        fname[:-4]: os.path.join(tile_embed_dir, fname)\n",
    "        for fname in fnames\n",
    "        if fname.endswith(\".pkl\") and fname[:6] in set(df.index)\n",
    "    }\n",
    "\n",
    "    # keys are slide ids, values are the paths\n",
    "    return tile_embed_paths\n",
    "\n",
    "\n",
    "included_models = {\"gigapath\": \"tile\", \"prism\": \"slide\"}\n",
    "foundation_model = \"ensemble_\" + \"\".join(\n",
    "    [m[0] for m in included_models.keys()]\n",
    ")\n",
    "\n",
    "# get the paths for all included tile embeddings\n",
    "tile_encoders = [k for k, v in included_models.items() if v == \"tile\"]\n",
    "tile_embed_path_base = OUTPUT_DIR + \"/{model}/tile_embeddings_sorted\"\n",
    "tile_embed_paths = {\n",
    "    model: get_tile_embed_paths(tile_embed_path_base.format(model=model))\n",
    "    for model in tile_encoders\n",
    "}\n",
    "\n",
    "# get the path for the prism slide embeddings if included\n",
    "slide_embeds_path = None\n",
    "if \"prism\" in included_models:\n",
    "    slide_embeds_path = os.path.join(\n",
    "        OUTPUT_DIR, \"prism/slide_embeddings/prism_slide_embeds_perceiver.pkl\"\n",
    "    )\n",
    "\n",
    "# map specimens to slides\n",
    "slides_by_specimen = {spec: [] for spec in list(df.index)}\n",
    "for slide_name in tile_embed_paths[\"gigapath\"]:\n",
    "    spec = slide_name[:6]\n",
    "    if slides_by_specimen.get(spec) is not None:\n",
    "        slides_by_specimen[spec].append(slide_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "NUM_LABELS = 4\n",
    "PATIENCE = 10\n",
    "\n",
    "auroc_keys = [k + \"_auroc\" for k in [\"benign\", \"bowens\", \"bcc\", \"scc\"]]\n",
    "auprc_keys = [k + \"_auprc\" for k in [\"benign\", \"bowens\", \"bcc\", \"scc\"]]\n",
    "results = pd.DataFrame(\n",
    "    columns=[\"foundation_model\", \"aggregator\", \"classifier\", \"fold\"]\n",
    "    + auroc_keys\n",
    "    + auprc_keys\n",
    ")\n",
    "\n",
    "# set experiment-specific variables\n",
    "gated = False\n",
    "heads = 1\n",
    "aggregator = \"abmil\"\n",
    "save_directory = \"ungated\"\n",
    "model_name = \"chkpts/{foundation_model}-{aggregator}-{heads}_heads-fold-{i}.pt\"\n",
    "exp_name = f\"{foundation_model}/abmil/{save_directory}/{foundation_model}-3_hidden-{heads}_heads\"\n",
    "\n",
    "evaluator = Evaluator(Label)\n",
    "\n",
    "# for each fold, train and validate while saving the best models\n",
    "# then evaluate the final outputs by generating curves using Evaluator\n",
    "for i in range(len(specimens_by_fold)):\n",
    "    print(f\"--------------------FOLD    {i + 1}--------------------\")\n",
    "    # get dataloaders and embed dims for loaded embeddings\n",
    "    train_set, val_set = get_datasets(\n",
    "        i,\n",
    "        specimens_by_fold,\n",
    "        slides_by_specimen,\n",
    "        labels_dict,\n",
    "        list(tile_embed_paths.values()),\n",
    "        [slide_embeds_path] if slide_embeds_path is not None else None,\n",
    "    )\n",
    "\n",
    "    model = EnsembleClassifier(\n",
    "        tile_encoder_dim=[1536], slide_encoder_dim=1280, out_features=4\n",
    "    ).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_model_weights = None\n",
    "    best_model_data = {\"ids\": None, \"labels\": None, \"probs\": None}\n",
    "    patience = PATIENCE\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = train_epoch(\n",
    "            model,\n",
    "            train_set,\n",
    "            optim,\n",
    "            loss_fn,\n",
    "            BATCH_SIZE,\n",
    "            device,\n",
    "        )\n",
    "        val_loss, labels, probs, ids = val_epoch(\n",
    "            model,\n",
    "            val_set,\n",
    "            device,\n",
    "            loss_fn,\n",
    "        )\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            best_model_data[\"ids\"] = ids\n",
    "            best_model_data[\"labels\"] = labels\n",
    "            best_model_data[\"probs\"] = probs\n",
    "            patience = PATIENCE\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                break\n",
    "\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            spaces = \" \" * (4 - len(str(epoch + 1)))\n",
    "            print(\n",
    "                f\"--------------------EPOCH{spaces}{epoch + 1}--------------------\"\n",
    "            )\n",
    "            print(f\"train loss: {train_loss:0.6f}\")\n",
    "            print(f\"val loss:   {val_loss:0.6f}\")\n",
    "            print()\n",
    "\n",
    "    # save the best model\n",
    "    torch.save(\n",
    "        best_model_weights,\n",
    "        os.path.join(\n",
    "            OUTPUT_DIR,\n",
    "            model_name.format(\n",
    "                foundation_model=foundation_model,\n",
    "                aggregator=aggregator,\n",
    "                heads=heads,\n",
    "                i=i,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # extract relevant data from val results for best model\n",
    "    ids, probs = Evaluator.get_spec_level_probs(\n",
    "        best_model_data[\"ids\"], best_model_data[\"probs\"]\n",
    "    )\n",
    "    labels_onehot_val = np.array(itemgetter(*ids)(labels_onehot))\n",
    "\n",
    "    evaluator.fold(probs, labels_onehot_val, i, len(specimens_by_fold))\n",
    "    auroc = roc_auc_score(\n",
    "        labels_onehot_val, probs, average=None, multi_class=\"ovr\"\n",
    "    )\n",
    "    auroc_dict = {auroc_keys[i]: v for i, v in enumerate(auroc)}\n",
    "\n",
    "    auprc = average_precision_score(labels_onehot_val, probs, average=None)\n",
    "    auprc_dict = {auprc_keys[i]: v for i, v in enumerate(auprc)}\n",
    "\n",
    "    model_details = {}\n",
    "    model_details[\"foundation_model\"] = foundation_model\n",
    "    model_details[\"aggregator\"] = aggregator\n",
    "    model_details[\"classifier\"] = \"MLP\"\n",
    "    model_details[\"fold\"] = i\n",
    "    model_details = model_details | auroc_dict | auprc_dict\n",
    "    details_df = pd.Series(model_details)\n",
    "    results = pd.concat([results, details_df.to_frame().T], ignore_index=True)\n",
    "\n",
    "evaluator.finalize(class_freqs)\n",
    "evaluator.save_figs(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\n",
    "    \"outputs/experiments_by_fold.csv\", sep=\"|\", mode=\"a\", header=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
