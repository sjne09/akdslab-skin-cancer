{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied and pasted from prov-gigapath implementation\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
    "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
    "    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
    "    grid = np.stack(grid, axis=0)\n",
    "\n",
    "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    if cls_token:\n",
    "        pos_embed = np.concatenate(\n",
    "            [np.zeros([1, embed_dim]), pos_embed], axis=0\n",
    "        )\n",
    "    return pos_embed\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "\n",
    "    # use half of dimensions to encode grid_h\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(\n",
    "        embed_dim // 2, grid[0]\n",
    "    )  # (H*W, D/2)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(\n",
    "        embed_dim // 2, grid[1]\n",
    "    )  # (H*W, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_h, emb_w], axis=1)  # (H*W, D)\n",
    "    return emb\n",
    "\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=float)\n",
    "    omega /= embed_dim / 2.0\n",
    "    omega = 1.0 / 10000**omega  # (D/2,)\n",
    "\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    out = np.einsum(\"m,d->md\", pos, omega)  # (M, D/2), outer product\n",
    "\n",
    "    emb_sin = np.sin(out)  # (M, D/2)\n",
    "    emb_cos = np.cos(out)  # (M, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
    "    return emb\n",
    "\n",
    "\n",
    "def coords_to_pos(coords, tile_size: int = 256):\n",
    "    \"\"\"\n",
    "    This function is used to convert the coordinates to the positional indices\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    coords: torch.Tensor\n",
    "        The coordinates of the patches, of shape [N, L, 2]\n",
    "    output: torch.Tensor\n",
    "        The positional indices of the patches, of shape [N, L]\n",
    "    \"\"\"\n",
    "    slide_ngrids = 1000\n",
    "    coords_ = torch.floor(coords / tile_size)\n",
    "    pos = coords_[..., 0] * slide_ngrids + coords_[..., 1]\n",
    "    return pos.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "tile_embed_dir = \"/opt/gpudata/skin-cancer/outputs/uni/tile_embeddings_sorted\"\n",
    "fnames = os.listdir(tile_embed_dir)\n",
    "tile_embed_paths = [\n",
    "    os.path.join(tile_embed_dir, fname)\n",
    "    for fname in fnames\n",
    "    if fname.endswith(\".pkl\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "idx = np.random.randint(0, len(tile_embed_paths) - 1)\n",
    "with open(tile_embed_paths[idx], \"rb\") as f:\n",
    "    embeds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gigapath positional embeds and get positional data, then get corresponding embeds\n",
    "gp_pos = get_2d_sincos_pos_embed(1024, 1000, False)\n",
    "pos_from_coords = coords_to_pos(embeds[\"coords\"])\n",
    "gp_pos_emb = gp_pos[pos_from_coords, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pos_embedding import PositionalEmbedding, PositionalEmbeddingAlt\n",
    "\n",
    "# load my implementation of the gigapath embeds and get embeds\n",
    "my_pos = PositionalEmbedding(1024, 1000)\n",
    "my_pos_emb = my_pos.forward(embeds[\"pos\"].to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mean embedding implementation and get embeds\n",
    "alt = PositionalEmbeddingAlt(1024, 1000)\n",
    "alt_emb = alt.forward(embeds[\"pos\"].to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# plot similarity to view structure of embeddings\n",
    "similarity = gp_pos_emb @ gp_pos_emb.T\n",
    "plt.imshow(similarity, cmap=\"inferno\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "similarity = my_pos_emb @ my_pos_emb.T\n",
    "plt.imshow(similarity, cmap=\"inferno\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "similarity = alt_emb @ alt_emb.T\n",
    "plt.imshow(similarity, cmap=\"inferno\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the whole thing again but with contiguous coordinates\n",
    "x = torch.arange(0, 20).repeat_interleave(100)\n",
    "y = torch.arange(0, 20).repeat(100)\n",
    "xy = torch.stack((x, y), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_from_coords = coords_to_pos(xy * 256)\n",
    "gp_pos_emb = gp_pos[pos_from_coords, :]\n",
    "my_pos_emb = my_pos(xy)\n",
    "alt_emb = alt(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "similarity = gp_pos_emb @ gp_pos_emb.T\n",
    "plt.imshow(similarity, cmap=\"inferno\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "similarity = my_pos_emb @ my_pos_emb.T\n",
    "plt.imshow(similarity, cmap=\"inferno\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "similarity = alt_emb @ alt_emb.T\n",
    "plt.imshow(similarity, cmap=\"inferno\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
