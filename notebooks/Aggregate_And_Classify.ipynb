{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.chdir(\"..\")\n",
    "\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the labels data with folds\n",
    "from utils.load_data import load_data\n",
    "\n",
    "label_path = os.path.join(DATA_DIR, \"labels/labels.csv\")\n",
    "fold_path = os.path.join(DATA_DIR, \"folds.json\")\n",
    "\n",
    "df = load_data(label_path=label_path, fold_path=fold_path)\n",
    "df = df.set_index(\"specimen_id\")\n",
    "labels_onehot = df[[\"bowens\", \"scc\", \"bcc\", \"na\"]]\n",
    "labels_dict = {row.name: int(row[\"label\"]) for _, row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the absolute path for each slide's set of tile embeddings\n",
    "tile_embed_dir = \"/opt/gpudata/skin-cancer/outputs/uni/tile_embeddings\"\n",
    "fnames = os.listdir(tile_embed_dir)\n",
    "tile_embed_paths = [\n",
    "    os.path.join(tile_embed_dir, fname)\n",
    "    for fname in fnames\n",
    "    if fname.endswith(\".pkl\") and fname[:6] in set(df.index)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of specimens within each fold\n",
    "specimens_by_fold = df.groupby(\"fold\").groups\n",
    "specimens_by_fold = [list(specs) for specs in specimens_by_fold.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map specimens to slides\n",
    "slides_by_specimen = {spec: [] for spec in list(df.index)}\n",
    "for slide in tile_embed_paths:\n",
    "    slide_name = os.path.basename(slide)[:-4]\n",
    "    spec = slide_name[:6]\n",
    "    if slides_by_specimen.get(spec) is not None:\n",
    "        slides_by_specimen[spec].append(slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_models.Label import Label\n",
    "\n",
    "spec_freqs = {\n",
    "    label: df[label].value_counts(normalize=True).iloc[1]\n",
    "    for label in Label._member_names_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim,\n",
    "    loss_fn: nn.Module,\n",
    ") -> float:\n",
    "    agg_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for i, sample in enumerate(dataloader):\n",
    "        embeds = sample[\"tile_embeds\"]\n",
    "        label = sample[\"label\"]\n",
    "        if len(embeds.shape) < 3:\n",
    "            embeds = embeds.unsqueeze(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(embeds.to(device), sample[\"coords\"].to(device))\n",
    "        if len(output.shape) < 2:\n",
    "            output = output.unsqueeze(0)\n",
    "        loss = loss_fn(output, label.to(device))\n",
    "        agg_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    return agg_loss / (i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def val_epoch(\n",
    "    model: nn.Module, dataloader: DataLoader, loss_fn: nn.Module\n",
    ") -> Tuple[float, List[float]]:\n",
    "    agg_loss = 0.0\n",
    "    outputs = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(dataloader):\n",
    "            embeds = sample[\"tile_embeds\"]\n",
    "            label = sample[\"label\"]\n",
    "            if len(embeds.shape) < 3:\n",
    "                embeds = embeds.unsqueeze(0)\n",
    "\n",
    "            output = model(embeds.to(device), sample[\"coords\"].to(device))\n",
    "            if len(output.shape) < 2:\n",
    "                output = output.unsqueeze(0)\n",
    "            loss = loss_fn(output, label.to(device))\n",
    "            outputs.append(torch.softmax(output.detach().cpu(), dim=-1))\n",
    "            labels.append(label)\n",
    "            ids.extend(sample[\"id\"])\n",
    "            agg_loss += loss.item()\n",
    "    outputs = torch.cat(outputs)\n",
    "    labels = torch.cat(labels)\n",
    "    return agg_loss / (i + 1), labels, outputs, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# dictionaries to keep eval curve results for each label\n",
    "tprs = {label: [] for label in Label._member_names_}\n",
    "aucs = {label: [] for label in Label._member_names_}\n",
    "precisions = {label: [] for label in Label._member_names_}\n",
    "aps = {label: [] for label in Label._member_names_}\n",
    "\n",
    "# mean x vals and axes for curves\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "roc_fig, roc_axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "prc_fig, prc_axs = plt.subplots(2, 2, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_models.datasets import SlideEncodingDataset, collate_tile_embeds\n",
    "from utils.split import train_val_split_slides, train_val_split_labels\n",
    "\n",
    "\n",
    "def get_loaders(\n",
    "    val_fold: int,\n",
    "    specimens_by_fold: List[List[str]],\n",
    "    slides_by_specimen: Dict[str, List[str]],\n",
    "    labels_by_specimen: Dict[str, int],\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    train, val = train_val_split_slides(\n",
    "        val_fold=val_fold,\n",
    "        specimens_by_fold=specimens_by_fold,\n",
    "        slides_by_specimen=slides_by_specimen,\n",
    "    )\n",
    "    train_labels, val_labels = train_val_split_labels(\n",
    "        val_fold=val_fold,\n",
    "        labels_by_specimen=labels_by_specimen,\n",
    "        specimens_by_fold=specimens_by_fold,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        SlideEncodingDataset(train, train_labels),\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_tile_embeds,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        SlideEncodingDataset(val, val_labels),\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_tile_embeds,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from models.vanilla_attn import VanillaAttentionAggregator\n",
    "from utils.eval import get_spec_level_probs, plot_eval\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "NUM_LABELS = 4\n",
    "PATIENCE = 10\n",
    "\n",
    "\n",
    "for i in range(len(specimens_by_fold)):\n",
    "    print(f\"--------------------FOLD    {i + 1}--------------------\")\n",
    "    # get dataloaders and embed dims for loaded embeddings\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        i, specimens_by_fold, slides_by_specimen, labels_dict\n",
    "    )\n",
    "    for sample in train_loader:\n",
    "        embed_dim = sample[\"tile_embeds\"].shape[-1]\n",
    "        break\n",
    "\n",
    "    model = VanillaAttentionAggregator(embed_dim, NUM_LABELS, 1, True).to(\n",
    "        device\n",
    "    )\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_model_weights = None\n",
    "    best_model_data = {\"ids\": None, \"labels\": None, \"probs\": None}\n",
    "    patience = PATIENCE\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = train_epoch(model, train_loader, optim, loss_fn)\n",
    "        val_loss, labels, probs, ids = val_epoch(model, val_loader, loss_fn)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            best_model_data[\"ids\"] = ids\n",
    "            best_model_data[\"labels\"] = labels\n",
    "            best_model_data[\"probs\"] = probs\n",
    "            patience = PATIENCE\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                break\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            spaces = \" \" * (4 - len(str(epoch + 1)))\n",
    "            print(\n",
    "                f\"--------------------EPOCH{spaces}{epoch + 1}--------------------\"\n",
    "            )\n",
    "            print(f\"train loss: {train_loss:0.6f}\")\n",
    "            print(f\"val loss:   {val_loss:0.6f}\")\n",
    "            print()\n",
    "\n",
    "    # save the best model\n",
    "    torch.save(\n",
    "        best_model_weights,\n",
    "        os.path.join(OUTPUT_DIR, f\"chkpts/uni-vanil-pool-fold-{i}\"),\n",
    "    )\n",
    "\n",
    "    # extract relevant data from val results for best model\n",
    "    ids, probs = get_spec_level_probs(\n",
    "        best_model_data[\"ids\"], best_model_data[\"probs\"]\n",
    "    )\n",
    "    labels_onehot_val = labels_onehot.loc[ids]\n",
    "\n",
    "    # for each predicted class, plot the current classifier's eval\n",
    "    # and retain relevant data in dicts\n",
    "    for j, class_of_interest in enumerate(Label._member_names_):\n",
    "        interp_tpr, roc_auc = plot_eval(\n",
    "            mean_x=mean_fpr,\n",
    "            onehot_labels=labels_onehot_val[f\"{class_of_interest}\"],\n",
    "            probs=probs[:, Label[class_of_interest].value],\n",
    "            ax=roc_axs[j // 2][j % 2],\n",
    "            plot_type=\"ROC\",\n",
    "            fold_idx=i,\n",
    "            plot_chance_level=i == len(specimens_by_fold) - 1,\n",
    "        )\n",
    "        tprs[class_of_interest].append(interp_tpr)\n",
    "        aucs[class_of_interest].append(roc_auc)\n",
    "\n",
    "        interp_precision, average_precision = plot_eval(\n",
    "            mean_x=mean_recall,\n",
    "            onehot_labels=labels_onehot_val[f\"{class_of_interest}\"],\n",
    "            probs=probs[:, Label[class_of_interest].value],\n",
    "            ax=prc_axs[j // 2][j % 2],\n",
    "            plot_type=\"PRC\",\n",
    "            fold_idx=i,\n",
    "            plot_chance_level=False,\n",
    "        )\n",
    "        precisions[class_of_interest].append(interp_precision)\n",
    "        aps[class_of_interest].append(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval import create_mean_curve\n",
    "\n",
    "exp_name = \"uni/vanilla/pool/uni-3_hidden\"\n",
    "\n",
    "# plot the mean eval curves\n",
    "for j, class_of_interest in enumerate(Label._member_names_):\n",
    "    create_mean_curve(\n",
    "        mean_fpr,\n",
    "        tprs[class_of_interest],\n",
    "        aucs[class_of_interest],\n",
    "        roc_axs[j // 2][j % 2],\n",
    "        \"ROC\",\n",
    "        class_of_interest,\n",
    "    )\n",
    "\n",
    "    prc_ax = prc_axs[j // 2][j % 2]\n",
    "    create_mean_curve(\n",
    "        mean_recall,\n",
    "        precisions[class_of_interest],\n",
    "        aps[class_of_interest],\n",
    "        prc_ax,\n",
    "        \"PRC\",\n",
    "        class_of_interest,\n",
    "    )\n",
    "\n",
    "    # add chance line for PRC == label freq at specimen level\n",
    "    prc_ax.axhline(\n",
    "        spec_freqs[class_of_interest],\n",
    "        linestyle=\"--\",\n",
    "        label=r\"Chance level (AP = %0.2f)\" % (spec_freqs[class_of_interest]),\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "    # reorder legend\n",
    "    handles, labs = prc_ax.get_legend_handles_labels()\n",
    "    handles[-1], handles[-3] = handles[-3], handles[-1]\n",
    "    labs[-1], labs[-3] = labs[-3], labs[-1]\n",
    "    prc_ax.legend(handles=handles, labels=labs, loc=\"lower right\")\n",
    "\n",
    "# roc_fig.show()\n",
    "roc_fig.savefig(f\"outputs/{exp_name}-roc.png\")\n",
    "# prc_fig.show()\n",
    "prc_fig.savefig(f\"outputs/{exp_name}-prc.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
