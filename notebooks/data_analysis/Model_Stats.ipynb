{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "DATA_DIR = os.environ[\"DATA_DIR\"]\n",
    "OUTPUT_DIR = os.environ[\"OUTPUT_DIR\"]\n",
    "\n",
    "gpus = [\"0\"]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(gpus)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_params(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model: nn.Module) -> float:\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_all_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_slide = os.path.join(DATA_DIR, \"tiles/output/660060-1.svs\")\n",
    "tile_paths = [\n",
    "    os.path.join(sample_slide, fname)\n",
    "    for fname in os.listdir(sample_slide)\n",
    "    if fname.endswith(\".png\")\n",
    "]\n",
    "num_tiles = len(tile_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {\"UNI\": None, \"gigapath\": None, \"prism\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNI\n",
    "import time\n",
    "from scripts.uni_embed import load_model, run_inference\n",
    "\n",
    "\n",
    "model, transform = load_model(device)\n",
    "start = time.perf_counter()\n",
    "inf = run_inference(tile_paths, model, transform, 128, device)\n",
    "elapsed = time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"UNI\"] = {\n",
    "    \"architecture\": \"ViT large, patch size 16\",\n",
    "    \"params\": count_trainable_params(model),\n",
    "    \"model_size\": f\"{get_model_size(model):.2f}MB\",\n",
    "    \"runtime\": f\"{(elapsed / (num_tiles / 1000)):.4f} sec/k tiles\",\n",
    "    \"embed_dim\": inf[\"tile_embeds\"].shape[-1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRISM\n",
    "from scripts.prism_embed import load_model, run_inference\n",
    "\n",
    "model, transform = load_model()\n",
    "start = time.perf_counter()\n",
    "inf = run_inference(tile_paths, model, transform, 128, device)\n",
    "elapsed = time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"prism\"] = {\n",
    "    \"architecture\": \"ViT huge, patch size 14\",\n",
    "    \"params\": count_trainable_params(model),\n",
    "    \"model_size\": f\"{get_model_size(model):.2f}MB\",\n",
    "    \"runtime\": f\"{(elapsed / (num_tiles / 1000)):.4f} sec/k tiles\",\n",
    "    \"embed_dim\": inf[\"tile_embeds\"].shape[-1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov-gigapath\n",
    "from scripts.gigapath_embed import load_tile_encoder, run_inference\n",
    "\n",
    "model, transform = load_tile_encoder()\n",
    "start = time.perf_counter()\n",
    "inf = run_inference(tile_paths, model, transform, 128, device)\n",
    "elapsed = time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats[\"gigapath\"] = {\n",
    "    \"architecture\": \"ViT giant, patch size 14\",\n",
    "    \"params\": count_trainable_params(model),\n",
    "    \"model_size\": f\"{get_model_size(model):.2f}MB\",\n",
    "    \"runtime\": f\"{(elapsed / (num_tiles / 1000)):.4f} sec/k tiles\",\n",
    "    \"embed_dim\": inf[\"tile_embeds\"].shape[-1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(model_stats)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
