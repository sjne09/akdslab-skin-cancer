{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_processing.datasets import (\n",
    "    SlideClassificationDataset,\n",
    "    collate_slide_embeds,\n",
    ")\n",
    "from data_processing.label import Label\n",
    "from evaluation.eval import Evaluator\n",
    "from models import MLP\n",
    "from models.training.train import train_epoch, val_epoch\n",
    "from models.training.load import get_loaders\n",
    "from data_processing.load_data import load_data\n",
    "from data_processing.split import (\n",
    "    train_val_split_labels,\n",
    "    train_val_split_slides,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the labels data with folds\n",
    "label_path = os.path.join(DATA_DIR, \"labels/labels.csv\")\n",
    "fold_path = os.path.join(DATA_DIR, \"folds.json\")\n",
    "embedding_path = os.path.join(\n",
    "    OUTPUT_DIR, \"prism/slide_embeddings/prism_slide_embeds_GAP.pkl\"\n",
    ")\n",
    "\n",
    "df = load_data(\n",
    "    label_path=label_path, embedding_path=embedding_path, fold_path=fold_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map specimen id to a list of WSIs\n",
    "slides_by_specimen = df.groupby(\"specimen_id\").groups\n",
    "slides_by_specimen = {k: list(v) for k, v in slides_by_specimen.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.reset_index()\n",
    "    .drop(columns=[\"slide_id\"])\n",
    "    .drop_duplicates(subset=[\"specimen_id\"])\n",
    "    .set_index(\"specimen_id\")\n",
    ")\n",
    "labels_onehot = df[Label._member_names_].to_dict(orient=\"split\", index=True)\n",
    "labels_onehot = {\n",
    "    k: np.array(labels_onehot[\"data\"][i])\n",
    "    for i, k in enumerate(labels_onehot[\"index\"])\n",
    "}\n",
    "labels_dict = {row.name: int(row[\"label\"]) for _, row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of specimens within each fold\n",
    "specimens_by_fold = (\n",
    "    df.reset_index()[[\"specimen_id\", \"fold\"]]\n",
    "    .drop_duplicates()\n",
    "    .set_index(\"specimen_id\")\n",
    "    .groupby(\"fold\")\n",
    "    .groups\n",
    ")\n",
    "specimens_by_fold = [list(specs) for specs in specimens_by_fold.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freqs = {\n",
    "    label: df[label].value_counts(normalize=True).iloc[1]\n",
    "    for label in Label._member_names_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "    val_fold: int,\n",
    "    specimens_by_fold: List[List[str]],\n",
    "    slides_by_specimen: Dict[str, List[str]],\n",
    "    labels_by_specimen: Dict[str, int],\n",
    "    slide_embeds_path: str,\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    train, val = train_val_split_slides(\n",
    "        val_fold=val_fold,\n",
    "        specimens_by_fold=specimens_by_fold,\n",
    "        slides_by_specimen=slides_by_specimen,\n",
    "    )\n",
    "    train_labels, val_labels = train_val_split_labels(\n",
    "        val_fold=val_fold,\n",
    "        labels_by_specimen=labels_by_specimen,\n",
    "        specimens_by_fold=specimens_by_fold,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        SlideClassificationDataset(slide_embeds_path, train, train_labels),\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_slide_embeds,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        SlideClassificationDataset(slide_embeds_path, val, val_labels),\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_slide_embeds,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training.load import get_loaders\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "NUM_LABELS = 4\n",
    "PATIENCE = 10\n",
    "\n",
    "foundation_model = \"prism\"\n",
    "aggregator = \"PRISM_test\"\n",
    "model_name = (\n",
    "    \"chkpts/{foundation_model}/{foundation_model}-{aggregator}-fold-{i}.pt\"\n",
    ")\n",
    "exp_name = \"{foundation_model}/testing/{foundation_model}-3_hidden\"\n",
    "\n",
    "evaluator = Evaluator(Label)\n",
    "auroc_keys = [k + \"_auroc\" for k in [\"benign\", \"bowens\", \"bcc\", \"scc\"]]\n",
    "auprc_keys = [k + \"_auprc\" for k in [\"benign\", \"bowens\", \"bcc\", \"scc\"]]\n",
    "results = pd.DataFrame(\n",
    "    columns=[\"foundation_model\", \"aggregator\", \"classifier\", \"fold\"]\n",
    "    + auroc_keys\n",
    "    + auprc_keys\n",
    ")\n",
    "\n",
    "for i in range(len(specimens_by_fold)):\n",
    "    print(f\"--------------------FOLD    {i + 1}--------------------\")\n",
    "    # get dataloaders and embed dims for loaded embeddings\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        val_fold=i,\n",
    "        specimens_by_fold=specimens_by_fold,\n",
    "        slides_by_specimen=slides_by_specimen,\n",
    "        labels_by_specimen=labels_dict,\n",
    "        train_dataset_class=partial(\n",
    "            SlideClassificationDataset, slide_embeds_path=embedding_path\n",
    "        ),\n",
    "        val_dataset_class=partial(\n",
    "            SlideClassificationDataset, slide_embeds_path=embedding_path\n",
    "        ),\n",
    "        collate_fn=collate_slide_embeds,\n",
    "    )\n",
    "\n",
    "    for sample in train_loader:\n",
    "        embed_dim = sample[\"slide_embed\"].shape[-1]\n",
    "        break\n",
    "\n",
    "    model = MLP(embed_dim, [1024, 512, 256], NUM_LABELS).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_model_weights = None\n",
    "    best_model_data = {\"ids\": None, \"labels\": None, \"probs\": None}\n",
    "    patience = PATIENCE\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optim,\n",
    "            loss_fn,\n",
    "            BATCH_SIZE,\n",
    "            [\"slide_embed\"],\n",
    "            \"label\",\n",
    "            device,\n",
    "        )\n",
    "        val_loss, labels, probs, ids = val_epoch(\n",
    "            model, val_loader, device, [\"slide_embed\"], \"label\", loss_fn\n",
    "        )\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            best_model_data[\"ids\"] = ids\n",
    "            best_model_data[\"labels\"] = labels\n",
    "            best_model_data[\"probs\"] = probs\n",
    "            patience = PATIENCE\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                break\n",
    "\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            spaces = \" \" * (4 - len(str(epoch + 1)))\n",
    "            print(\n",
    "                f\"--------------------EPOCH{spaces}{epoch + 1}--------------------\"\n",
    "            )\n",
    "            print(f\"train loss: {train_loss:0.6f}\")\n",
    "            print(f\"val loss:   {val_loss:0.6f}\")\n",
    "            print()\n",
    "\n",
    "    # save the best model\n",
    "    torch.save(\n",
    "        best_model_weights,\n",
    "        os.path.join(\n",
    "            OUTPUT_DIR,\n",
    "            model_name.format(\n",
    "                foundation_model=foundation_model, aggregator=aggregator, i=i\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    evaluator.fold(i, best_model_data, len(specimens_by_fold))\n",
    "\n",
    "evaluator.finalize(class_freqs)\n",
    "evaluator.save_figs(exp_name.format(foundation_model=foundation_model))\n",
    "evaluator.results.to_csv(\n",
    "    \"outputs/experiments_by_fold.csv\", sep=\"|\", mode=\"a\", header=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
