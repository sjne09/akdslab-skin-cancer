{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract attn weights from the models - use `uni` env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.chdir(\"..\")\n",
    "\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "from models.agg import MILClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gigapath_best_model = \"/opt/gpudata/skin-cancer/outputs/chkpts/gigapath/gigapath-abmil-1_head-fold-1.pt\"\n",
    "uni_best_model = (\n",
    "    \"/opt/gpudata/skin-cancer/outputs/chkpts/uni/uni-abmil-1_head-fold-3.pt\"\n",
    ")\n",
    "prism_local_model = \"/opt/gpudata/skin-cancer/models/models--paige-ai--Prism/snapshots/cd2eae7b1e6e51f3664e1a575c5bfe7045cc37d4\"\n",
    "hf_cache_dir = \"/opt/gpudata/skin-cancer/models\"\n",
    "tile_embeddings_dir = \"/opt/gpudata/skin-cancer/outputs/{foundation_model}/tile_embeddings_sorted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def load_model(model_name):\n",
    "    if model_name == \"uni\":\n",
    "        model = MILClassifier(1024, 4, 1, False).to(device)\n",
    "        model.load_state_dict(torch.load(uni_best_model))\n",
    "    elif model_name == \"gigapath\":\n",
    "        model = MILClassifier(1536, 4, 1, False).to(device)\n",
    "        model.load_state_dict(torch.load(gigapath_best_model))\n",
    "    else:\n",
    "        model = AutoModel.from_pretrained(\n",
    "            prism_local_model,\n",
    "            cache_dir=hf_cache_dir,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model, model_name, slide_id):\n",
    "    with open(\n",
    "        os.path.join(\n",
    "            tile_embeddings_dir.format(foundation_model=model_name),\n",
    "            f\"{slide_id}.pkl\",\n",
    "        ),\n",
    "        \"rb\",\n",
    "    ) as f:\n",
    "        tile_embeddings = pickle.load(f)\n",
    "\n",
    "    tile_coords = []\n",
    "    for coords in tile_embeddings[\"coords\"]:\n",
    "        tile_coords.append({\"x\": int(coords[0]), \"y\": int(coords[1])})\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if model_name == \"prism\":\n",
    "        with torch.autocast(\"cuda\", torch.float16), torch.inference_mode():\n",
    "            out = model.slide_representations(\n",
    "                tile_embeddings=tile_embeddings[\"tile_embeds\"]\n",
    "                .unsqueeze(0)\n",
    "                .to(device)\n",
    "            )\n",
    "            weights = (\n",
    "                out[\"xattn_weights\"].squeeze().max(dim=0).values.detach().cpu()\n",
    "            ).numpy()\n",
    "    else:\n",
    "        with torch.inference_mode():\n",
    "            _, weights = model(\n",
    "                tile_embeddings[\"tile_embeds\"].unsqueeze(0).to(device),\n",
    "                tile_embeddings[\"pos\"].unsqueeze(0).to(device),\n",
    "            )\n",
    "            weights = weights.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    return weights, tile_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide_ids = [\"660529-6\", \"660370-5\"] # bowens\n",
    "# slide_ids = [\"660042-3\", \"660506-6\"]  # bcc\n",
    "# slide_ids = [\"660058-1\"] # scc\n",
    "slide_ids = [\n",
    "    \"660524-4\",\n",
    "    \"660192-4\",\n",
    "    \"660465-4\",\n",
    "    \"660192-1\",\n",
    "    \"660535-4\",\n",
    "    \"660415-3\",\n",
    "    \"660152-2\",\n",
    "    \"660447-2\",\n",
    "    \"660122-1\",\n",
    "    \"660032-3\",\n",
    "]  # bowens round 2\n",
    "models = [\"prism\", \"uni\", \"gigapath\"]\n",
    "\n",
    "for m in models:\n",
    "    for slide_id in slide_ids:\n",
    "        model = load_model(m)\n",
    "        weights, coords = get_weights(model, m, slide_id)\n",
    "        with open(f\"attn_comps/weights/{m}-{slide_id}-weights.pkl\", \"wb\") as f:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    \"weights\": weights,\n",
    "                    \"coords\": coords,\n",
    "                },\n",
    "                f,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the heatmaps - use `gigapath` env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from gigapath.preprocessing.data.foreground_segmentation import LoadROId\n",
    "from matplotlib import collections, patches, pyplot as plt\n",
    "from monai.data.wsi_reader import WSIReader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_slide(id):\n",
    "    sample = {\n",
    "        \"image\": f\"/opt/gpudata/skin-cancer/data/slides/{id}.svs\",\n",
    "        \"slide_id\": id,\n",
    "    }\n",
    "    loader = LoadROId(\n",
    "        WSIReader(backend=\"OpenSlide\"),\n",
    "        level=0,\n",
    "        margin=0,\n",
    "        foreground_threshold=None,\n",
    "    )\n",
    "    sample = loader(sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(model_name, slide_id):\n",
    "    sample = load_slide(slide_id)\n",
    "    with open(\n",
    "        f\"attn_comps/weights/{model_name}-{slide_id}-weights-norm.pkl\", \"rb\"\n",
    "    ) as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    weights = data[\"weights\"]\n",
    "    tile_coords = data[\"coords\"]\n",
    "\n",
    "    # scaled_weights = np.log(weights + 1e-6)\n",
    "    slide_image = sample[\"image\"]\n",
    "    downscale_factor = sample[\"scale\"]\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(15, 5))\n",
    "    ax.imshow(slide_image.transpose(1, 2, 0))\n",
    "    rects = []\n",
    "    for tile_info in tile_coords:\n",
    "        # change coordinate to the current level from level-0\n",
    "        # tile location is in the original image cooridnate, while the slide image is after selecting ROI\n",
    "        xy = (\n",
    "            (tile_info[\"x\"] - sample[\"origin\"][0]) / downscale_factor,\n",
    "            (tile_info[\"y\"] - sample[\"origin\"][1]) / downscale_factor,\n",
    "        )\n",
    "        rects.append(patches.Rectangle(xy, 256, 256))\n",
    "    pc = collections.PatchCollection(rects, alpha=1, cmap=\"inferno\")\n",
    "    pc.set_array(weights)\n",
    "    pc.set_clim(vmin=vmin[slide_id], vmax=vmax[slide_id])\n",
    "    ax.add_collection(pc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.colorbar(pc, ax=ax)\n",
    "    plt.title(f\"{model_name}, slide {slide_id}\")\n",
    "    plt.savefig(f\"attn_comps/{model_name}-{slide_id}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide_ids = [\"660529-6\", \"660370-5\"] # bowens\n",
    "# slide_ids = [\"660042-3\", \"660506-6\"]  # bcc\n",
    "# slide_ids = [\"660058-1\"] # scc\n",
    "slide_ids = [\n",
    "    \"660524-4\",\n",
    "    \"660192-4\",\n",
    "    # \"660465-4\",\n",
    "    # \"660192-1\",\n",
    "    # \"660535-4\",\n",
    "    # \"660415-3\",\n",
    "    # \"660152-2\",\n",
    "    # \"660447-2\",\n",
    "    # \"660122-1\",\n",
    "    # \"660032-3\",\n",
    "]  # bowens round 2\n",
    "models = [\"prism\", \"uni\", \"gigapath\"]\n",
    "\n",
    "vmin = {}\n",
    "vmax = {}\n",
    "coords = None\n",
    "for slide_id in slide_ids:\n",
    "    weights_dict = {}\n",
    "    weights = []\n",
    "    for m in models:\n",
    "        with open(f\"attn_comps/weights/{m}-{slide_id}-weights.pkl\", \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            coords = data[\"coords\"]\n",
    "\n",
    "            # clip weights to control for outliers\n",
    "            min_threshold = np.percentile(data[\"weights\"], 1)\n",
    "            max_threshold = np.percentile(data[\"weights\"], 99)\n",
    "            clipped_scores = np.clip(\n",
    "                data[\"weights\"], min_threshold, max_threshold\n",
    "            )\n",
    "\n",
    "            weights_dict[m] = clipped_scores\n",
    "            weights.append(clipped_scores)\n",
    "\n",
    "    concat_weights = np.concatenate(weights)\n",
    "    mean = concat_weights.mean()\n",
    "    std = concat_weights.std()\n",
    "    normalized = (concat_weights - mean) / std\n",
    "    weights_dict = {k: (v - mean) / std for k, v in weights_dict.items()}\n",
    "    vmin[slide_id] = normalized.min()\n",
    "    vmax[slide_id] = normalized.max()\n",
    "\n",
    "    for m in models:\n",
    "        with open(\n",
    "            f\"attn_comps/weights/{m}-{slide_id}-weights-norm.pkl\", \"wb\"\n",
    "        ) as f:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    \"weights\": weights_dict[m],\n",
    "                    \"coords\": coords,\n",
    "                },\n",
    "                f,\n",
    "            )\n",
    "\n",
    "\n",
    "for m in models:\n",
    "    for slide_id in slide_ids:\n",
    "        print(f\"processing {slide_id} for {m}\")\n",
    "        plot_image(m, slide_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gigapath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
